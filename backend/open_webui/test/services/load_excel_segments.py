"""
åŠ è½½maxkbå¯¼å‡ºçš„Excelåˆ†æ®µæ–‡ä»¶å¹¶æµ‹è¯•æ£€ç´¢
æ ¼å¼ï¼šç« èŠ‚ã€åˆ†æ®µå†…å®¹ã€é—®é¢˜ï¼ˆé€‰å¡«ï¼Œå•å…ƒæ ¼å†…ä¸€è¡Œä¸€ä¸ªï¼‰
"""
import sys
from pathlib import Path

sys.path.insert(0, '/home/zeroerr-ai72/openwebui-zeroerr/backend')

import pandas as pd
from langchain_core.documents import Document
from open_webui.test.services.vllm_embeddings import VLLMEmbeddings


def load_excel_segments(file_path: Path):
    """åŠ è½½Excelåˆ†æ®µæ•°æ®"""
    excel_file = pd.ExcelFile(file_path)
    
    all_docs = []
    
    for sheet_name in excel_file.sheet_names:
        df = pd.read_excel(file_path, sheet_name=sheet_name)
        
        for idx, row in df.iterrows():
            # æå–åˆ†æ®µå†…å®¹
            content = None
            questions = None
            chapter = None
            
            # æŸ¥æ‰¾å†…å®¹åˆ—
            for col in df.columns:
                val = row[col]
                if pd.notna(val):
                    col_str = str(col)
                    val_str = str(val).strip()
                    
                    if 'å†…å®¹' in col_str and not content:
                        content = val_str
                    # æŸ¥æ‰¾ç« èŠ‚åˆ—
                    elif 'ç« èŠ‚' in col_str and not chapter:
                        chapter = val_str
                    # æŸ¥æ‰¾é—®é¢˜åˆ—
                    elif 'é—®é¢˜' in col_str and not questions:
                        questions = val_str
            
            # åˆ›å»ºDocument
            if content:
                doc = Document(
                    page_content=content,
                    metadata={
                        'source': file_path.name,
                        'sheet': sheet_name,
                        'row': idx,
                        'chapter': chapter or '',
                        'questions': questions or ''
                    }
                )
                all_docs.append(doc)
    
    return all_docs


def test_retrieval(docs, queries):
    """æµ‹è¯•æ£€ç´¢"""
    print(f"\n{'='*70}")
    print("ğŸ” æµ‹è¯•æ£€ç´¢")
    print(f"{'='*70}")
    
    # å‘é‡åŒ–
    embeddings = VLLMEmbeddings()
    texts = [doc.page_content for doc in docs]
    
    print(f"\nğŸ“ å‘é‡åŒ– {len(texts)} ä¸ªæ–‡æ¡£...")
    vectors = embeddings.embed_documents(texts)
    
    # å­˜å‚¨å‘é‡
    vector_store = {i: {'doc': doc, 'vector': vec} for i, (doc, vec) in enumerate(zip(docs, vectors))}
    
    # æµ‹è¯•æŸ¥è¯¢
    for query in queries:
        print(f"\n{'='*70}")
        print(f"æŸ¥è¯¢: {query}")
        print(f"{'='*70}")
        
        # å‘é‡åŒ–æŸ¥è¯¢
        query_vec = embeddings.embed_query(query)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        import numpy as np
        query_array = np.array(query_vec)
        
        results = []
        for idx, item in vector_store.items():
            doc_vec = np.array(item['vector'])
            similarity = np.dot(query_array, doc_vec) / (
                np.linalg.norm(query_array) * np.linalg.norm(doc_vec)
            )
            results.append((item['doc'], similarity))
        
        # æ’åº
        results.sort(key=lambda x: x[1], reverse=True)
        
        # æ˜¾ç¤ºå‰5ä¸ªç»“æœ
        print(f"\nTop 5 ç»“æœ:")
        for i, (doc, score) in enumerate(results[:5], 1):
            print(f"\n{i}. [ç›¸ä¼¼åº¦: {score:.4f}]")
            print(f"   ç« èŠ‚: {doc.metadata.get('chapter', 'N/A')}")
            print(f"   å†…å®¹: {doc.page_content[:200]}...")
            if doc.metadata.get('questions'):
                print(f"   é—®é¢˜: {doc.metadata['questions']}")


def main():
    excel_file = Path("/home/zeroerr-ai72/openwebui-zeroerr/backend/data/uploads/knowledge/748b54f6-73b0-4efb-87c3-15c166556d6f/manual/EtherCAT&CANopené€šè®¯æ‰‹å†Œ-20250919.xlsx")
    
    print("ğŸš€ åŠ è½½Excelåˆ†æ®µæ–‡ä»¶")
    print("="*70)
    
    # åŠ è½½æ–‡æ¡£
    docs = load_excel_segments(excel_file)
    print(f"\nâœ… åŠ è½½å®Œæˆ: {len(docs)} ä¸ªåˆ†æ®µ")
    
    # æ˜¾ç¤ºå‰3ä¸ªåˆ†æ®µçš„å…ƒæ•°æ®
    print("\nå‰3ä¸ªåˆ†æ®µ:")
    for i, doc in enumerate(docs[:3], 1):
        print(f"{i}. {doc.page_content[:100]}...")
        print(f"   å…ƒæ•°æ®: {doc.metadata}")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "å…³èŠ‚çš„é‡å¤å®šä½ç²¾åº¦æ˜¯å¤šå°‘å•Šï¼Ÿ"
    ]
    
    test_retrieval(docs, test_queries)
    
    print("\n" + "="*70)
    print("âœ… æµ‹è¯•å®Œæˆ")
    print("="*70)


if __name__ == "__main__":
    main()
